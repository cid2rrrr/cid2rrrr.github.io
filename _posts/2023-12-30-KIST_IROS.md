---
layout: post
title:  "Paper: Zero-Shot Audiovisual Segmentation"
info: "'s Paper rejected by IROS 2024"
tech : "IROS 2024"
type: SJ Lee
---


## [Google Drive](https://drive.google.com/file/d/1dUS2NsZELKa9v8Yb4SLkRDR32Jek7gbJ/view?usp=sharing)


## Automatic Classification of Drum Sounds for Robotic Music Performance
Abstractâ€” In the future, intelligent robots will be capable of collaborating with humans in singing songs or playing musical instruments. Billions of songs created by humans so far are important data for such robots to learn and analyze. This paper introduces a new strategy for automatic drum transcription using CNN and RNN. After learning mel-spectrogram images of 53,976 drum sounds, the CNN model classifies which instrument is hit for each drum sound. After that, the RNN model trained with 9,432 drum sequence data corrects some classes that have low probability in the CNN model. The results show that the proposed method achieves the drum classification accuracy that is comparable to other methods. Finally, the KIST robot drummer successfully performs music songs using reconstructed drum scores.

